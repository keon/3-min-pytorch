# 순차적인 데이터를 처리하는 RNN

RNN을 활용하여 영화 리뷰 감정 분석과 기계번역을 해봅니다.

  * [개념] RNN 기초
  * [프로젝트 1] 영화 리뷰 감정 분석
  * [프로젝트 2] Seq2Seq 기계 번역
  * 더 보기

## RNN 기초

우리가 지금까지 만든 딥러닝 모델들은 입력받은 데이터를 분류 하는 정도에 그쳤습니다.
물론 인공신경망을 통한 분류 작업은 컴퓨터과학에선 분명 큰 도약이지만
실제 인간의 뇌가 할 수 있는 일들에 비하면 이는 매우 간단한 일입니다.
그렇다면 뇌의 기능 중 인공신경망이 지니지 못한 결정적인 능력은 무엇일까요.
물론 사람의 뇌는 인공신경망과 비교하면 그 능력이
너무나도 무궁무진하여 콕 집어 말할 수는 없습니다.
하지만 개인적으로는, 연이어 일어나는 사건들의 상호 작용을 이해하는 능력,
즉 여러 사건들의 순서를 기반으로 전체적인 상황에 대해 논리적인 결론을 내는 능력이라고 생각합니다.
소설을 읽는 것을 상상해 보세요.
우리는 소설 속에서 일어난 잘잘한 사건들의 원인과 결과,
그리고 순서를 인지함으로써 소설의 전체적인 줄거리를 이해합니다.
'사건 A 가 일어난 후 그 때문에 B 가 일어났으니 해피엔딩이다.' 같은 논리적인 결론을 내는것 처럼 말이죠.
이처럼 연이어 발생한 사건과 데이터들의 관계와 순서를 이해하고 종합해 이를 기반으로
학습하는 새로운 형태의 신경망이 바로 이번 장의 토픽인 RNN(Recurrent Neural Network)입니다.

RNN 은 지금까지 우리가 배워온 신경망과는 약간 다른 형태의 데이터셋을 입력받습니다.
앞 장의 Fashion MNIST 데이터셋 속의 모든 데이터는
같은 크기의 특성값을 지닌 하나의 벡터 형태를 띄고 있었습니다.
이에 비해 RNN에 입력되는 '순차적 데이터(Sequential Data)'는 일반적으로
여러개의 벡터들이 특정한 순서대로 나열된 구조를 지니고 있습니다.
이러한 데이터를 입력받은 RNN은 데이터 속 벡터들의 상관관계와 순서정보를 학습하여
하나의 고정된 크기의 벡터로 압축시켜주는 기능을 합니다.
이해를 돕기 위해 아주 간단한 예를 들어 보겠습니다.

```
문장 1: ‘What a good lecture it was.’
문장 2: ‘It was a good lecture.’
```

만약 문장 속 단어들이 특성값을 지닌 벡터로 나타내어 질 수 있다면 
첫번째 문장 1에는 벡터가 6개가 있는 반면,
두번째 문장 2에는 벡터가 5개가 있게 됩니다.
이렇게 데이터끼리 서로 다른 차원수를 가진 상황에서
RNN은 문장 내 단어들의 흐름을 학습해 벡터의 배열이라고도 할 수 있는 문장을
하나의 고정된 크기의 벡터로 바꿔줍니다.
즉 RNN 을 거친 문장 1과 2는 같은 수의 특성값을 지니게 됩니다.

데이터와 데이터의 상관관계와 상호작용을 학습 할 수 있다는 점에서 RNN이 매우
어렵고 새로운 개념이라는 생각이 들 수도 있습니다.
하지만 RNN은 1982년 존 홉필드(John Hopfield)에 의해 
처음으로 발명된 이후 지금까지 30년도 더 넘게 연구되어 왔습니다.
실제로 RNN을 학습시키는 방법은 1990 년 폴 J. 웨보스(Paul J. Werbos)
가 ‘시간에 따른 역전파 알고리즘(Backpropagation Through Time)’을 명확히 정의함으로써 완성되었고,
현재는 LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit) 등
새로운 형태의 RNN이 발명되었습니다.
이러한 순환신경망들은 텍스트 감정 분석(Text Sentiment Analysis),
기계 번역(Machine Translation), 이미지 캡셔닝(Image Captioning)
등의 다양한 분야에 활발하게 적용되고 있습니다.








